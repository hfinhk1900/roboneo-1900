### OpenAI 图像 API 最佳实践与实施指南

本文档总结了在本项目中，实现一个生产级的“图像到风格化贴纸”功能的最佳实践和完整步骤。该流程复刻了 OpenAI 的核心逻辑，确保了高质量的输出和服务的健壮性。

#### 一、技术栈概览

| 环节 | 模型/API | 职责 |
| :--- | :--- | :--- |
| **1. 提示词工程** | `gpt-4o` (`/v1/chat/completions`) | 将用户的模糊请求，优化为图像模型能精确理解的、风格锁定的具体指令。 |
| **2. 图像风格转换** | `gpt-image-1` (`/v1/images/edits`) | 核心步骤，接收原始图片和优化后的指令，生成新风格的图片。 |
| **3. 安全审核** | 内置于 `gpt-image-1` | OpenAI 自动对输入和输出内容进行安全审核，无需手动调用审核接口。 |
| **4. 图像预处理** | `sharp` (Node.js 库) | 在服务器端将用户上传的图片处理成符合 API 要求的标准格式。 |

#### 二、端到端实施步骤

**第1步：服务器端图像预处理**

*   **目的**: OpenAI 的 `/v1/images/edits` 接口有严格的输入要求。此步骤旨在将任意用户输入标准化。
*   **要求**:
    *   **格式**: 必须是 **PNG** 格式。
    *   **尺寸**: 必须是**正方形**，`gpt-image-1` 模型推荐使用 **`1024x1024`**。
    *   **透明通道 (Alpha Channel)**: 必须是 **RGBA**。透明像素被用作“蒙版（mask）”，告知模型哪些区域是可编辑的。为了让模型编辑整张图，我们需要一个完整的 Alpha 通道。
    *   **大小**: 文件体积必须 ≤ 4MB。
*   **实施**:
    1.  使用 `sharp` 库读取用户上传的图片 buffer。
    2.  调用 `.resize()` 方法，设置尺寸为 `1024, 1024`，并配置 `{ fit: 'contain', background: { r: 0, g: 0, b: 0, alpha: 0 } }`。这会将图片等比缩放并置于一个透明的方形画布中央。
    3.  链式调用 `.png()` 确保输出为 PNG 格式。
    4.  链式调用 `.ensureAlpha()` 确保图片拥有透明通道。
    5.  最终处理过的图片 buffer 用于后续步骤。

**第2步：使用 GPT-4o 进行提示词工程**

*   **目的**: 将用户的简单想法（如“iOS 风格”）转换成能稳定产出高质量结果的详细、具体的指令。这是保证风格一致性的关键。
*   **实施**:
    1.  调用 `/v1/chat/completions` API。
    2.  构造 `messages` 数组：
        *   `role: "system"`: 提供一个“系统指令”，用于设定 AI 的角色和最终输出的风格基调。例如：“你是一个为图像编辑模型（DALL-E 3）优化的提示词工程师。返回一个能将上传图片重塑为官方 Apple iOS emoji 贴纸风格的英文提示词...”。
        *   `role: "user"`: 传入用户选择的风格对应的基础描述。
    3.  从 API 响应的 `choices[0].message.content` 中提取优化后的提示词。

**第3步：核心图像生成 (`/v1/images/edits`)**

*   **目的**: 这是执行实际风格转换的核心 API 调用。
*   **实施**:
    1.  创建一个 `FormData` 对象。
    2.  **关键参数**:
        *   `image`: 附加上一步预处理过的图片文件（`File` 或 `Blob` 对象）。
        *   `prompt`: 附加上一步从 `gpt-4o` 获取的优化后提示词。
        *   `model`: 指定为 `'gpt-image-1'` (注意：此模型要求您的 OpenAI 组织账户通过验证)。
        *   `size`: `'1024x1024'`。
        *   `n`: `1` (生成一张图片)。
    3.  向 `https://api.openai.com/v1/images/edits` 发送 POST 请求。
    4.  **解析响应 (关键！)**:
        *   成功的响应 **不会** 包含 `url` 字段。
        *   图片数据以 Base64 字符串的形式，直接存在于 `data[0].b64_json` 字段中。

**第4步：处理内置安全审核**

*   **最佳实践**: 对于 `gpt-image-1` 这样的新一代多模态模型，**OpenAI 会在其后端自动进行内容安全审核**。我们**不需要也**不应该**手动调用 `/v1/moderations` 接口**。
*   **实施**:
    *   **移除所有手动的 `moderateInput` 和 `moderateOutput` 调用**。
    *   在主 API 逻辑的 `try...catch` 块中，准备好捕获由 `dalleStyleTransfer` 函数（即 `/v1/images/edits` 调用）直接抛出的错误。
    *   如果 OpenAI 的内置审核检测到违规内容，API 调用会直接失败，并返回一个 `400 Bad Request` 的错误。我们的代码应该捕获这个错误，并向客户端返回相应的提示。

**第5步：向客户端交付结果**

*   **实施**:
    1.  从第3步获取到的 `b64_json` 字符串。
    2.  将其包装在一个 Data URI 中：`data:image/png;base64,${b64_json}`。
    3.  在 JSON 响应中将这个完整的 Data URI 发送给客户端。这种方式简化了前端逻辑，图片可以直接用于 `<img>` 标签的 `src` 属性。

#### 三、成本与性能

*   **成本构成**:
    1.  **GPT-4o 提示词优化**: 约 **`$0.0018`** (基于约 184 个输入 tokens 和 58 个输出 tokens)。
    2.  **gpt-image-1 图像生成**: **`$0.04`** (每张 `1024x1024` 图像)。
*   **单次生成总成本**: 约 **`$0.042`** (4.2 美分)。
*   **端到端延迟**: 约 **20-30 秒**。

#### 四、调试与关键经验

*   **组织验证**: 使用 `gpt-image-1` 模型的前提是 OpenAI 组织账户必须**通过验证**。
*   **响应格式**: `/v1/images/edits` 端点返回的是包含 Base64 数据的 **`b64_json`** 字段，而不是 `url`。
*   **安全审核**: 不要手动调用 `/v1/moderations` 来审核图片，这会导致 `400 Bad Request` 错误。应依赖模型的**内置审核**机制。
*   **调试工具**: 创建一个独立的测试脚本（如 `scripts/debug-image-to-sticker-improved.ts`）是验证端到端流程、快速定位问题的关键。
