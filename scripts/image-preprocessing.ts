/**
 * å›¾ç‰‡é¢„å¤„ç†å·¥å…· - æ¨¡ä»¿ ChatGPT å®˜æ–¹çš„å¤„ç†æ–¹å¼
 * å°†ä»»æ„æ ¼å¼çš„å›¾ç‰‡è½¬æ¢ä¸º OpenAI API å…¼å®¹çš„æ ¼å¼
 */

import * as fs from 'fs';
import * as path from 'path';

// éœ€è¦å®‰è£…: npm install sharp
// sharp æ˜¯ä¸€ä¸ªé«˜æ€§èƒ½çš„å›¾ç‰‡å¤„ç†åº“
async function preprocessImageForOpenAI() {
  // æ£€æŸ¥æ˜¯å¦å®‰è£…äº† sharp
  let sharp: any;
  try {
    sharp = require('sharp');
  } catch (error) {
    console.log('âŒ éœ€è¦å®‰è£… sharp åº“: npm install sharp');
    console.log('ðŸ’¡ Sharp æ˜¯ Node.js æœ€å¼ºå¤§çš„å›¾ç‰‡å¤„ç†åº“ï¼Œç”¨äºŽæ ¼å¼è½¬æ¢');
    return;
  }

  const inputPath = path.join(process.cwd(), 'public', 'test-img.png');
  const outputPath = path.join(
    process.cwd(),
    'public',
    'test-img-processed.png'
  );

  if (!fs.existsSync(inputPath)) {
    console.log('âŒ æ‰¾ä¸åˆ°æµ‹è¯•å›¾ç‰‡:', inputPath);
    return;
  }

  try {
    console.log('ðŸ”„ å¼€å§‹å›¾ç‰‡é¢„å¤„ç†...');

    // èŽ·å–åŽŸå§‹å›¾ç‰‡ä¿¡æ¯
    const metadata = await sharp(inputPath).metadata();
    console.log('ðŸ“Š åŽŸå§‹å›¾ç‰‡ä¿¡æ¯:', {
      format: metadata.format,
      width: metadata.width,
      height: metadata.height,
      channels: metadata.channels,
      hasAlpha: metadata.hasAlpha,
      size: `${Math.round(fs.statSync(inputPath).size / 1024)}KB`,
    });

    // æ¨¡ä»¿ ChatGPT çš„é¢„å¤„ç†é€»è¾‘
    let processedImage = sharp(inputPath);

    // 1. ç¡®ä¿æ˜¯ RGBA æ ¼å¼ï¼ˆ4ä¸ªé€šé“ï¼šR, G, B, Aï¼‰
    if (!metadata.hasAlpha) {
      console.log('ðŸ”§ æ·»åŠ é€æ˜Žé€šé“ (RGB â†’ RGBA)');
      processedImage = processedImage.ensureAlpha();
    }

    // 2. è°ƒæ•´å°ºå¯¸åˆ° OpenAI æ”¯æŒçš„æ¯”ä¾‹
    const { width = 0, height = 0 } = metadata;
    const aspectRatio = width / height;

    // OpenAI æ”¯æŒçš„å°ºå¯¸
    const supportedSizes = [
      { w: 1024, h: 1024, ratio: 1.0 }, // æ­£æ–¹å½¢
      { w: 1024, h: 1536, ratio: 0.667 }, // è‚–åƒ
      { w: 1536, h: 1024, ratio: 1.5 }, // é£Žæ™¯
    ];

    // é€‰æ‹©æœ€æŽ¥è¿‘çš„æ”¯æŒå°ºå¯¸
    const closest = supportedSizes.reduce((prev, curr) =>
      Math.abs(curr.ratio - aspectRatio) < Math.abs(prev.ratio - aspectRatio)
        ? curr
        : prev
    );

    const targetWidth: number = closest.w;
    const targetHeight: number = closest.h;

    console.log(
      `ðŸ“ è°ƒæ•´å°ºå¯¸: ${width}x${height} â†’ ${targetWidth}x${targetHeight}`
    );

    // 3. ä½¿ç”¨ contain æ¨¡å¼ä¿æŒåŽŸå§‹å†…å®¹ï¼Œæ·»åŠ é€æ˜Žè¾¹æ¡†
    processedImage = processedImage.resize(targetWidth, targetHeight, {
      fit: 'contain',
      background: { r: 0, g: 0, b: 0, alpha: 0 }, // é€æ˜ŽèƒŒæ™¯
    });

    // 4. ç¡®ä¿è¾“å‡ºä¸º PNG æ ¼å¼
    processedImage = processedImage.png({
      compressionLevel: 6, // ä¸­ç­‰åŽ‹ç¼©
      adaptiveFiltering: true,
    });

    // ä¿å­˜å¤„ç†åŽçš„å›¾ç‰‡
    await processedImage.toFile(outputPath);

    // æ£€æŸ¥å¤„ç†ç»“æžœ
    const processedMetadata = await sharp(outputPath).metadata();
    const processedSize = fs.statSync(outputPath).size;

    console.log('âœ… é¢„å¤„ç†å®Œæˆ!');
    console.log('ðŸ“Š å¤„ç†åŽå›¾ç‰‡ä¿¡æ¯:', {
      format: processedMetadata.format,
      width: processedMetadata.width,
      height: processedMetadata.height,
      channels: processedMetadata.channels,
      hasAlpha: processedMetadata.hasAlpha,
      size: `${Math.round(processedSize / 1024)}KB`,
    });

    // éªŒè¯æ˜¯å¦ç¬¦åˆ OpenAI è¦æ±‚
    const isValid =
      processedMetadata.format === 'png' &&
      processedMetadata.hasAlpha &&
      processedSize < 4 * 1024 * 1024 && // < 4MB
      [1024, 1536].includes(processedMetadata.width!) &&
      [1024, 1536].includes(processedMetadata.height!);

    if (isValid) {
      console.log('ðŸŽ‰ å›¾ç‰‡å·²ç¬¦åˆ OpenAI API è¦æ±‚!');
      console.log(`ðŸ’¾ å¤„ç†åŽçš„å›¾ç‰‡: ${outputPath}`);
    } else {
      console.log('âš ï¸  å›¾ç‰‡å¯èƒ½ä»æœ‰å…¼å®¹æ€§é—®é¢˜');
    }

    return outputPath;
  } catch (error) {
    console.error('âŒ å›¾ç‰‡é¢„å¤„ç†å¤±è´¥:', error);
  }
}

// è¿è¡Œé¢„å¤„ç†
if (require.main === module) {
  preprocessImageForOpenAI().catch(console.error);
}

export { preprocessImageForOpenAI };
